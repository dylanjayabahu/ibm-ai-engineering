# see GAN intro from lesson 1

GAN = generative adversarial network 
    used fr gathering synthetic data 
    generate high quality images, music, and text 


generator creates realistic data, discriminator distinguishes between the 
together they get better and better 

continue the loop until generate makes data so good the discriminator cant tell it apart from real data

GAN Applications:
    - image generation to create realistic images 
    - image to image translation, convert one kind of image to another (e.g. sketch to photograph)
    - text to image synthesis generates images from text 
    - data augmentation 


Making a GAN:
    see code below
    can also generate images during training for monitoring purposes 

# implement GAN in keras 

generator_input_dim = 100

def build_generator():
    model = tf.Keras.Sequential()
    modeadd(Dense(128, input_dim=generator_input_dim))
    model.add(LeakyReLU(alpha=0.01))
    model.add(Dense,784, activation='tanh')
    return model 
    

def build_discriminator():
    model = tf.Keras.Sequential()
    model.add(Dense(128, input_shape=(784,)))
    model.add(LeakyReLU(alpha=0.01)) # leaky relu is used specifically in GANS because it stabilizes training
    model.add(Dense(1, activation='sigmoid'))
    return model

discriminator = build_discriminator()
discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

generator = build_generator()

# make GAN by combining generator and discriminator
discriminator.trainable=False # only applied to the gan; we never recompile discriminator itself 
gan_input = Input(shape=(generator_input_dim, ))
generated_image = generator(gan_input)
gan_output = discriminator(generated_image)
gan = Model(gan_input, gan_output)

gan.compile(optimizer='adam', loss='binary_crossentropy')


# need custom training loop so u can alternate back and forth between generator and discriminator 
def train_gan(gan, generator, discriminator, x_train, epochs=400, batch_size=128):
    for epoch in range(epochs):

        #make noise as input for generator
        noise = np.random.normal(0, 1, (batch)size, generator_input_dim)
        generated_images = generator.predict(noise)


        #get random set of actual images 
        idx = np.random.randint(0, x_train.shape[0], batch_size)
        real_images = x_train[idx]

        # labels for real/fake images 
        real_labels = np.ones((batch_size, 1))
        fake_labels = np.zeros((batch_size, 1))


        # get training loss on discriminator on real/fake images
        d_loss_real = discriminator.train_on_batch(real_images, real_labels)
        d_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)

        # compute average loss
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)


        # now train generator on new noise throug GAN model 
            # remember discriminator weights are frozen 

        noise = np.random.normal(0, 1, (batch_size, generator_input_dim))
        g_loss = gan.train_on_batch(noise, real_labels, return_dict=True)
            # since we are passing in real labels for the fake images we are making, 
            # we are teaching the generator to make images that the discriminator would predict as real

        print(f"Epoch {epoch}: d_loss={d_loss[0]}, g_loss={g_loss['loss']})
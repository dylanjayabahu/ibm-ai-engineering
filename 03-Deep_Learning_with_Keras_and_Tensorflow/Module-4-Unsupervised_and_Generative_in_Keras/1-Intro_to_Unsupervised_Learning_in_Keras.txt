Unsupervised Learning: find patterns without labels or predefined outcomes 
    no target variable
    understand underlying structure

Categories of Unsupervsed Learning:
    clustering
        grouping data points into clusters 
        similar data points in same cluster 
        e.g. k means and hierarchical clustering 

    association 
        find relationships between variables in large datasets 
        used in market basket analysis 
        e.g. A-priori and Eclat algorithms 

    dimensionality reduction 
        reduce number of random variables w/o much loss of info 
        optain principle variables
        PCA, UMAP, t-SNE


Autoencoders:
    type of nn used for dim reduction or feature learning 

    encoder:
        compresses input into a latent space representaiton 
    decoder:
        reconstructs input from latent space representation 

    
    latent space is the reduced dim vector 

    goal is to match reconstructed output to input with minimal diff


# autoencoder in keras 
input_layer = Input(shape=(784,))
encoded = Dense(64, activation='relu')(input_layer)
decoded = Dense(784, activation='sigmoid')(encoded)
autoencoder = Model(input_layer, decoded)
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')
autoencoder.summary()

# can train this on mnist or something else 
autoencoder.fit(X_train, X_train, ...)





Generative Adversarial Networks (GANs)
    
    system of two networks:
        generator network generates new data instances 
        discriminator network evaluates authenticity of generated data 

        generator tries to fool discriminator, discriminator tries to suss out fake data 

        the adversarial/competing process makes the generator make better and better data 
    

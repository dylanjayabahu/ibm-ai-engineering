IBM Professional Certificate in AI Engineering & Data Science — Summary
This repository contains projects and exercises completed as part of the IBM AI Engineering and IBM Data Science Professional Certificates. These programs emphasize hands-on, portfolio-ready experience in AI, machine learning, and data science, covering:

Core Machine Learning — Linear/Logistic Regression, Decision Trees, Supervised & Unsupervised Learning.

Deep Learning & Neural Networks — CNNs, RNNs, Transformers, Autoencoders, GANs, VAEs, Diffusion Models.

AI Frameworks & Libraries — Python, NumPy, Pandas, SciPy, Scikit-learn, PyTorch, TensorFlow, Keras.

Generative AI & LLMs — GPT, BERT, Hugging Face, Prompt Engineering, RAG, LangChain, PEFT, LoRA, QLoRA, RLHF, PPO, DPO.

Natural Language Processing — Tokenization, Embeddings, Word2Vec, Sequence-to-Sequence, BLEU metrics.

Model Deployment — Building and integrating models into real-world applications with APIs, Gradio, and watsonx.

Capstone & Applied Projects included developing AI solutions for real-world problems, optimizing LLMs for task-specific applications, and building an interactive QA bot using RAG with LangChain and vector databases.



Transcript from overview video:
Welcome to the IBM Professional Certificate (PC) Overview video, which introduces the two PCs this course is a part of. This course is part of both the IBM AI Engineering PC and the IBM Data Science PC. Each program offers a unique focus. The Data Science PC focuses on skills for data science careers, covering data cleaning, analysis, and predictive modeling with tools such as Python, SQL, Pandas, and NumPy to help you build a job-ready portfolio. The AI Engineering PC prepares data scientists, machine learning engineers, and software engineers for AI engineering. You'll learn to build, train, and deploy models, including large language models (LLMs), using Python and libraries like SciPy, Keras, PyTorch, and TensorFlow. If you're completing the IBM Data Science PC, the AI Engineering PC is an excellent next step to expand your AI expertise.
Play video starting at :1:5 and follow transcript1:05
Both programs emphasize hands-on learning with projects and labs, building real-world experience. These certifications with comprehensive curricula prepare you for a career in AI or data science. The IBM Data Science PC is suited for beginners, has no prerequisites, and is designed for anyone interested in data analysis, ML, and statistical modeling. The IBM AI Engineering PC is ideal for learners with knowledge of Python, data analysis, and generative AI basics, as well as experience with data science, machine learning (ML), or software engineering. The IBM AI Engineering PC covers topics and skills needed for an entry-level AI engineering role, including Introduction to AI and Deep Learning, ML and Deep Learning Frameworks, Supervised and Unsupervised Learning, Neural Networks, Convolutional Networks, and Recurrent Networks, Generative AI Models and LLMs, and working with Python libraries like SciPy, Scikit-learn, Keras, PyTorch, and TensorFlow. Each topic corresponds to a self-paced online course comprising 2-6 modules. Completing these courses and the required projects will help you get the IBM AI Engineering Professional Certificate.
Play video starting at :2:18 and follow transcript2:18
This Professional Certificate journey will introduce you to the fundamentals of machine learning using Python. You'll learn how to implement algorithms such as linear regression, logistic regression, decision trees, and more to build predictive models. By the end, you'll understand the key concepts of supervised learning and be able to apply these models to solve real-world problems. Deep learning basics and neural network architecture are essential for any AI professional. You will study unsupervised deep learning models such as autoencoders and restricted Boltzmann machines while also learning about convolutional and recurrent networks and building deep learning models and networks using the Keras library. Explore advanced deep learning techniques with Keras and TensorFlow 2.x, where you'll create custom layers and models and integrate Keras with TensorFlow for enhanced functionality. Develop convolutional neural networks (CNNs) and transformer models for sequential and time series data.
Play video starting at :3:17 and follow transcript3:17
The course also delves into unsupervised learning for model optimization, custom training loops, deep Q-networks (DQNs) for reinforcement learning, and an introduction to generative modeling and reinforcement learning principles. Develop essential skills in PyTorch for designing, training, and optimizing neural networks. You'll explore 2D tensors, derivatives, linear regression, and loss calculation, along with batch processing, gradient descent, and logistic regression, key techniques for building models in areas like image recognition and predictive analytics. Next, you will advance to complex deep learning techniques with PyTorch, covering Softmax regression, multi-class neural networks, and specialized architectures such as CNNs. You'll tackle overfitting, backpropagation, and vanishing gradient, and apply activation functions such as sigmoid, tanh, and ReLU. Hands-on projects and exercises will build expertise in creating robust models for real-world applications. The capstone project challenges you to apply deep learning expertise to a real-world problem.
Play video starting at :4:23 and follow transcript4:23
Choose a library, preprocess data, build and test a model, and validate its performance. A project report will showcase your model's effectiveness and your deep learning proficiency for your portfolio. Next, you will explore the types and applications of generative AI models, including RNNs, transformers, GANs, VAEs, and diffusion models. Understand key differences in training methods, tokenization techniques, and data preparation processes. Gain skills to work with large-language models, LLMs, like GPT and BERT. And learn to use tokenizers and data loaders, preparing you for implementing generative AI with libraries like Hugging Face. Delve into foundational NLP models, exploring one-hot encoding, embeddings, and Word2Vec for text representation.
Play video starting at :5:15 and follow transcript5:15
Build and optimize neural networks for tasks like document categorization and text generation using PyTorch and TorchText. Apply N-gram and sequence-to-sequence models for applications such as language translation and evaluate generated text quality with BLEU metrics. Gain expertise in transformer-based models like GPT and BERT, focusing on text classification, positional encoding, word embeddings, and attention mechanisms for contextual understanding. Dive into multi-head attention and apply GPT for language translation using decoder-based modeling. Explore BERT's bidirectional encoding with techniques like Massed Language Modeling (MLM) and Next Sentence Prediction (NSP), and implement these models in PyTorch for sophisticated language tasks. Explore advanced fine-tuning techniques for transformers using frameworks like Hugging Face and PyTorch. Learn to optimize large-language models (LLMs) with methods such as Parameter-Efficient Fine-Tuning (PEFT), Low-Rank Adaptation (LORA), Quantized Low-Rank Adaptation (QLORA), and Prompting.
Play video starting at :6:26 and follow transcript6:26
Gain hands-on experience in online labs, including loading, pre-training, and fine-tuning models to enhance performance for specific tasks. Refine your skills in fine-tuning LLMs with human feedback and direct preference. Explore instruction tuning with Hugging Face, reward modeling, and reinforcement learning techniques like RLHF and PPO. Gain hands-on experience in online labs focused on reward modeling, PPO, and DPO to optimize LLM performance for task-specific applications. Explore Retrieval Augmented Generation (RAG), Prompt Engineering, and LangChain concepts. Learn how RAG integrates external data and tokenizers for dynamic responses. Gain hands-on experience with LangChain tools, components, and LLMs to develop real-world applications.
Play video starting at :7:14 and follow transcript7:14
Apply these skills in online labs and a final project for practical, interview-ready experience. Finally, in the Applied Project-Based course, you'll enhance your knowledge of LangChain document loaders, apply text-splitting strategies, and use watsonx and vector databases to store and retrieve documents. Develop a QA bot with RAG and create a Gradio interface for model interaction. By the end, you'll have a project showcasing your generative AI skills for interviews. As you progress, quizzes and projects assess your understanding of the material, contributing to your completion of the course and earning a professional certificate. Wishing you the best on this journey!
